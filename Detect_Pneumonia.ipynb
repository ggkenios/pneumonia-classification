{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phV4ysCbPolU"
   },
   "source": [
    "# &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; Detect Pneumonia (2021)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5yNstt-Jimt"
   },
   "source": [
    "The code will be split in 5 main parts: <br>\n",
    "\n",
    "[<li> 1. Libraries](#1) <br>\n",
    "\n",
    "[<li> 2. Input](#2) <br>\n",
    "&emsp;  &emsp;  &ensp; [*2.1 Hyperparameters*](#2.1) <br>\n",
    "&emsp;  &emsp;  &ensp; [ *2.2 Data Directories*](#2.2) <br>\n",
    "&emsp;  &emsp;  &ensp; [*2.3 Generalization Variables*](#2.3) <br>\n",
    "\n",
    "[<li> 3. Data Preprocessing](#3) <br>\n",
    "&emsp;  &emsp;  &ensp; [*3.1 Setting Variables*](#3.1) <br>\n",
    "&emsp;  &emsp;  &ensp; [*3.2 Extra Data*](#3.2) <br>\n",
    "&emsp;  &emsp;  &ensp; [*3.3 Image Read*](#3.3) <br>\n",
    "&emsp;  &emsp;  &ensp; [*3.4 Cross Validation Split*](#3.4) <br>\n",
    "&emsp;  &emsp;  &ensp; [*3.5 Data Preperation*](#3.5) <br>\n",
    "\n",
    "[<li> 4. Model ](#4) <br>\n",
    "&emsp;  &emsp;  &ensp; [*4.1 Callbacks*](#4.1) <br>\n",
    "&emsp;  &emsp;  &ensp; [*4.2 Models* ](#4.2) <br>\n",
    "&emsp;  &emsp;  &ensp; [*4.3 Model Fit*](#4.3) <br>\n",
    "&emsp;  &emsp;  &ensp; [*4.4 Fine Tuning*](#4.4) <br>\n",
    "\n",
    "[<li> 5. Predictions ](#5) <br>\n",
    "&emsp;  &emsp;  &ensp; [ *5.1 Test Images*](#5.1) <br>\n",
    "&emsp;  &emsp;  &ensp; [ *5.2 Export Predictions*](#5.2) <br>\n",
    "&emsp;  &emsp;  &ensp; [ *5.3 Voting Ensemble*](#5.3) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHi50zB1OLOe"
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "##  1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70rdAZD9EK8m"
   },
   "outputs": [],
   "source": [
    "# Core\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TF\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "# Keras\n",
    "from keras import optimizers, losses\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjKmQL3hQcyV"
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2. Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40xE31gaTb2K"
   },
   "source": [
    "<a name=\"2.1\"></a>\n",
    "### &ensp; *2.1 Hyperparameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPiKVoAAUcyg"
   },
   "outputs": [],
   "source": [
    "selected_model = 'efficientnet_B3'\n",
    "\n",
    "Hyperparameters = {\n",
    "    'efficientnet_B0':{\n",
    "        'img_size':224,\n",
    "        'epochs': 25,\n",
    "        'batch_size':8,\n",
    "        'learning_rate':1e-4,\n",
    "        'fine_tune_epochs':25,\n",
    "        'unfreeze_layers':-25\n",
    "        },\n",
    "    'efficientnet_B1':{\n",
    "        'img_size':240,\n",
    "        'epochs': 50,\n",
    "        'batch_size':16,\n",
    "        'learning_rate':1e-3,\n",
    "        'fine_tune_epochs':80,\n",
    "        'unfreeze_layers':-40\n",
    "        },\n",
    "    'efficientnet_B2':{\n",
    "        'img_size':300,\n",
    "        'epochs': 50,\n",
    "        'batch_size':32,\n",
    "        'learning_rate':1e-3,\n",
    "        'fine_tune_epochs':80,\n",
    "        'unfreeze_layers':-25\n",
    "        },\n",
    "    'efficientnet_B3':{\n",
    "        'img_size':300,\n",
    "        'epochs': 40,\n",
    "        'batch_size':32,\n",
    "        'learning_rate':1e-3,\n",
    "        'fine_tune_epochs':50,\n",
    "        'unfreeze_layers':-30\n",
    "        },\n",
    "    'efficientnet_B4':{\n",
    "        'img_size':300,\n",
    "        'epochs': 25,\n",
    "        'batch_size':8,\n",
    "        'learning_rate':1e-4,\n",
    "        'fine_tune_epochs':25,\n",
    "        'unfreeze_layers':-30\n",
    "        },\n",
    "    'efficientnet_B5':{\n",
    "        'img_size':456,\n",
    "        'epochs': 25,\n",
    "        'batch_size':8,\n",
    "        'learning_rate':1e-4,\n",
    "        'fine_tune_epochs':25,\n",
    "        'unfreeze_layers':-25\n",
    "        }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKnEHYNeShT_"
   },
   "source": [
    "<a name=\"2.2\"></a>\n",
    "### &ensp; <font color='#008060'> *Data Directories* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rwh78AoyQn7F"
   },
   "outputs": [],
   "source": [
    "# Data paths\n",
    "train_path = '/Users/thxsg/OneDrive - International Hellenic University/1. IHU (2021)/5. Advanced Machine Learning/2. Homework/detect-pneumonia-fall-2021/train_images'\n",
    "test_path = '/Users/thxsg/OneDrive - International Hellenic University/1. IHU (2021)/5. Advanced Machine Learning/2. Homework/detect-pneumonia-fall-2021/test_images'\n",
    "label_csv = '/Users/thxsg/OneDrive - International Hellenic University/1. IHU (2021)/5. Advanced Machine Learning/2. Homework/detect-pneumonia-fall-2021/labels_train.csv'\n",
    "\n",
    "# Checkpoints\n",
    "path_c = '/Users/thxsg/Documents/Python Scripts/Checkpoints/'\n",
    "\n",
    "# Submissions\n",
    "sub = '/Users/thxsg/Documents/Python Scripts/Submissions/'\n",
    "\n",
    "# Softmax output for the model\n",
    "soft_single = '/Users/thxsg/Documents/Python Scripts/Soft-Votes.csv'\n",
    "\n",
    "# Softmaxes for Voting\n",
    "soft_path = '/Users/thxsg/OneDrive - International Hellenic University/1. IHU (2021)/5. Advanced Machine Learning/2. Homework/Attempts/Softmaxes'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEbzduVtVg4L"
   },
   "source": [
    "<a name=\"2.3\"></a>\n",
    "### &ensp; <font color='#008060'> *Generalization Variables* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmXG9NrMV5Cl"
   },
   "outputs": [],
   "source": [
    "colx = 'file_name'\n",
    "coly = 'class_id'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnOjI0o4WCao"
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "## <font color='#99b3e6'> 3. Data Preprocessing </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_liboCODSNoC"
   },
   "source": [
    "<a name=\"3.1\"></a>\n",
    "### &ensp; <font color='#008060'> *Setting Variables* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tujFAAsURwz7"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "img_size = Hyperparameters[selected_model]['img_size']\n",
    "epochs = Hyperparameters[selected_model]['epochs']\n",
    "batch_size = Hyperparameters[selected_model]['batch_size']\n",
    "learning_rate = Hyperparameters[selected_model]['learning_rate']\n",
    "fine_tune_epochs = Hyperparameters[selected_model]['fine_tune_epochs']\n",
    "unfreeze_layers = Hyperparameters[selected_model]['unfreeze_layers']\n",
    "\n",
    "# Other Variables\n",
    "labels = pd.read_csv(label_csv)\n",
    "classes = labels[coly].unique()\n",
    "num_cl = len(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwYaiHdTHUMA"
   },
   "source": [
    "<a name=\"3.2\"></a>\n",
    "### &ensp; <font color='#008060'> *Extra Data* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lE5_oXXBHTsB"
   },
   "outputs": [],
   "source": [
    "# Round the max number of images of the biggest class to a multiplier of 10,\n",
    "# for cross validation.\n",
    "lengths = []\n",
    "for i in range(0, num_cl):\n",
    "   exec('lengths.append(len(labels.loc[labels[coly] == ' + str(i) + ']))')\n",
    "maxlen = max(lengths)\n",
    "rr = - maxlen%10\n",
    "new_max = maxlen + rr\n",
    "\n",
    "# Then calculate the numbers for each class needed for data augmentation,\n",
    "# so each class has the same number of images.\n",
    "for i in range(0, num_cl):\n",
    "   exec('d' + str(i) + ' = new_max - len(labels.loc[labels[coly] == ' + str(i) + '])')\n",
    "\n",
    "# Creating the list for the images that will be augmented.\n",
    "exec('df_extra = labels.loc[labels[coly] == (num_cl - 1)].iloc[:d' + str(num_cl - 1) + ',][colx]')\n",
    "for i in range(num_cl - 2, -1, -1):\n",
    "  exec('df_extra = labels.loc[labels[coly] == ' + str(i) + '].iloc[:d' + str(i) + ',][colx].append(df_extra)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b6PN-F9Hh3O"
   },
   "source": [
    "<a name=\"3.3\"></a>\n",
    "### &ensp; <font color='#008060'> *Image Read* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sk_44LnV8PXM"
   },
   "outputs": [],
   "source": [
    "# Read Images\n",
    "x_train = []\n",
    "for img in labels[colx]:\n",
    "  img_array = cv2.imread(os.path.join(train_path, img))\n",
    "  res_array = cv2.resize(img_array, (img_size, img_size))\n",
    "  x_train.append(res_array)\n",
    "\n",
    "x_train_extra = []\n",
    "for img in df_extra:\n",
    "  img_array = cv2.imread(os.path.join(train_path, img))\n",
    "  res_array = cv2.resize(img_array, (img_size, img_size))\n",
    "  x_train_extra.append(res_array)\n",
    "\n",
    "# Transform Data to Tensorflow shape\n",
    "x_train = np.array(x_train).reshape(-1, img_size, img_size, 3)\n",
    "x_train_extra = np.array(x_train_extra).reshape(-1, img_size, img_size, 3)\n",
    "\n",
    "# Create augmentation function for extra data\n",
    "augm = keras.Sequential([layers.experimental.preprocessing.RandomZoom(0.05),])\n",
    "\n",
    "# Image data\n",
    "x_train = np.concatenate((x_train, augm(x_train_extra)))\n",
    "\n",
    "# Image data labels\n",
    "y_train = np.array(labels[coly])\n",
    "for i in range(0, num_cl):\n",
    "  exec('y_train = np.append(y_train, np.repeat(' + str(i) + ', d' + str(i) + '))')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2wUIQBW-Db4"
   },
   "source": [
    "<a name=\"3.4\"></a>\n",
    "### &ensp; <font color='#008060'> *Cross Validation Split* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLyaadTM6Rcn"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    stratify = y_train,\n",
    "    test_size = 0.1,\n",
    "    random_state = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfpDjOHqyrD7"
   },
   "source": [
    "<a name=\"3.5\"></a>\n",
    "### &ensp; <font color='#008060'> *Data Preperation* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_tzja6jRx1p"
   },
   "outputs": [],
   "source": [
    "# 1-hot-encoding, for categorical cross entropy\n",
    "y_train = to_categorical(y_train, num_cl)\n",
    "y_val = to_categorical(y_val, num_cl)\n",
    "\n",
    "# Prepare batches for the model\n",
    "train = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(batch_size)\n",
    "val = tf.data.Dataset.from_tensor_slices((x_val,y_val)).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ogpUn1Wzwi9"
   },
   "source": [
    "<a name=\"4\"></a>\n",
    "## <font color='#99b3e6'> 4. Model </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHEse4tT_BFW"
   },
   "source": [
    "<a name=\"4.1\"></a>\n",
    "### &ensp; <font color='#008060'> *Callbacks* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwLJHgvo24g2"
   },
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "checkpoint_acc = tf.keras.callbacks.ModelCheckpoint(filepath = path_c + 'Acc_CP - ' + selected_model + '.h5',\n",
    "                                                    monitor='val_acc',\n",
    "                                                    save_best_only=True)\n",
    "\n",
    "checkpoint_loss = tf.keras.callbacks.ModelCheckpoint(filepath = path_c + 'Loss_CP - ' + selected_model + '.h5',\n",
    "                                                     monitor='val_loss',\n",
    "                                                     save_best_only=True)\n",
    "\n",
    "checkpoint_acc_ft = tf.keras.callbacks.ModelCheckpoint(filepath = path_c + 'Acc_CP - ' + selected_model + ' FT.h5',\n",
    "                                                       monitor='val_acc',\n",
    "                                                       save_best_only=True)\n",
    "\n",
    "checkpoint_loss_ft = tf.keras.callbacks.ModelCheckpoint(filepath = path_c + 'Loss_CP - ' + selected_model + ' FT.h5',\n",
    "                                                        monitor='val_loss',\n",
    "                                                        save_best_only=True)\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=13,\n",
    "                                                     monitor='val_acc',\n",
    "                                                     restore_best_weights=True)\n",
    "\n",
    "# Learning Rate Modifiers\n",
    "def lr_schedule(epoch):\n",
    "    global epochs\n",
    "    global learning_rate\n",
    "\n",
    "    lr = learning_rate\n",
    "    if epoch > 0.9*epochs:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 0.8*epochs:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 0.6*epochs:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 0.4*epochs:\n",
    "        lr *= 1e-1\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=np.sqrt(0.1),\n",
    "                               mode='min',\n",
    "                               patience=3,\n",
    "                               min_lr=0.5e-6,\n",
    "                               verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGQWxCn0zNoW"
   },
   "source": [
    "<a name=\"4.2\"></a>\n",
    "### &ensp; <font color='#008060'> *Models* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xx8B8SkqeOlU"
   },
   "outputs": [],
   "source": [
    "def efficientnet_B0():\n",
    "        global num_cl\n",
    "        global img_size\n",
    "        \n",
    "        base_model = tf.keras.applications.EfficientNetB0(include_top=False,\n",
    "                                     weights='imagenet',\n",
    "                                     input_shape=(img_size, img_size, 3))\n",
    "        x = base_model.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        out = Dense(num_cl, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "          layer.trainable = False\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def efficientnet_B1():\n",
    "        global num_cl\n",
    "        global img_size\n",
    "\n",
    "        base_model = tf.keras.applications.EfficientNetB1(include_top=False,\n",
    "                                     weights='imagenet',\n",
    "                                     input_shape=(img_size, img_size, 3))\n",
    "        x = base_model.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        out = Dense(num_cl, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "          layer.trainable = False\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def efficientnet_B2():\n",
    "        global num_cl\n",
    "        global img_size\n",
    "\n",
    "        base_model = tf.keras.applications.EfficientNetB2(include_top=False,\n",
    "                                     weights='imagenet',\n",
    "                                     input_shape=(img_size, img_size, 3))\n",
    "        x = base_model.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        out = Dense(num_cl, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "          layer.trainable = False\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def efficientnet_B3():\n",
    "        global num_cl\n",
    "        global img_size\n",
    "\n",
    "        base_model = tf.keras.applications.EfficientNetB3(include_top=False,\n",
    "                                     weights='imagenet',\n",
    "                                     input_shape=(img_size, img_size, 3))\n",
    "        x = base_model.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        out = Dense(num_cl, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "          layer.trainable = False\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def efficientnet_B4():\n",
    "        global num_cl\n",
    "        global img_size\n",
    "\n",
    "        base_model = tf.keras.applications.EfficientNetB4(include_top=False,\n",
    "                                     weights='imagenet',\n",
    "                                     input_shape=(img_size, img_size, 3))\n",
    "        x = base_model.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        out = Dense(num_cl, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "          layer.trainable = False\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def efficientnet_B5():\n",
    "        global num_cl\n",
    "        global img_size\n",
    "\n",
    "        base_model = tf.keras.applications.EfficientNetB5(include_top=False,\n",
    "                                     weights='imagenet',\n",
    "                                     input_shape=(img_size, img_size, 3))\n",
    "        x = base_model.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(512, activation=None, kernel_regularizer = L1L2(l1=1e-5, l2=1e-3))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('swish')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        out = Dense(num_cl, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "          layer.trainable = False\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3W4Fl-0ZST-"
   },
   "outputs": [],
   "source": [
    "exec('model = ' + selected_model + '()')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate, decay = learning_rate * 0.1),\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqgKvvNuzVWj"
   },
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### &ensp; <font color='#008060'> *Model Fit* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2561599,
     "status": "ok",
     "timestamp": 1621525773176,
     "user": {
      "displayName": "He Did Nothing Wrong",
      "photoUrl": "",
      "userId": "14044224695877776076"
     },
     "user_tz": -180
    },
    "id": "20wQdiVldBkI",
    "outputId": "d6dcdb1d-73ff-43c2-a679-d9b835d17ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "189/189 [==============================] - 81s 352ms/step - loss: 1.6574 - acc: 0.6499 - val_loss: 1.1732 - val_acc: 0.8408\n",
      "Epoch 2/40\n",
      "189/189 [==============================] - 63s 331ms/step - loss: 1.2376 - acc: 0.7811 - val_loss: 1.0341 - val_acc: 0.8259\n",
      "Epoch 3/40\n",
      "189/189 [==============================] - 64s 338ms/step - loss: 1.0749 - acc: 0.8037 - val_loss: 0.9493 - val_acc: 0.8304\n",
      "Epoch 4/40\n",
      "189/189 [==============================] - 62s 327ms/step - loss: 0.9440 - acc: 0.8206 - val_loss: 0.8303 - val_acc: 0.8423\n",
      "Epoch 5/40\n",
      "189/189 [==============================] - 61s 324ms/step - loss: 0.8515 - acc: 0.8221 - val_loss: 0.7735 - val_acc: 0.8348\n",
      "Epoch 6/40\n",
      "189/189 [==============================] - 61s 325ms/step - loss: 0.7897 - acc: 0.8243 - val_loss: 0.7396 - val_acc: 0.8438\n",
      "Epoch 7/40\n",
      "189/189 [==============================] - 62s 328ms/step - loss: 0.7468 - acc: 0.8307 - val_loss: 0.6876 - val_acc: 0.8408\n",
      "Epoch 8/40\n",
      "189/189 [==============================] - 63s 331ms/step - loss: 0.7058 - acc: 0.8305 - val_loss: 0.6854 - val_acc: 0.8452\n",
      "Epoch 9/40\n",
      "189/189 [==============================] - 63s 332ms/step - loss: 0.6808 - acc: 0.8418 - val_loss: 0.6370 - val_acc: 0.8467\n",
      "Epoch 10/40\n",
      "189/189 [==============================] - 62s 327ms/step - loss: 0.6507 - acc: 0.8392 - val_loss: 0.6827 - val_acc: 0.8214\n",
      "Epoch 11/40\n",
      "189/189 [==============================] - 62s 326ms/step - loss: 0.6383 - acc: 0.8420 - val_loss: 0.5867 - val_acc: 0.8527\n",
      "Epoch 12/40\n",
      "189/189 [==============================] - 62s 328ms/step - loss: 0.6193 - acc: 0.8435 - val_loss: 0.5926 - val_acc: 0.8497\n",
      "Epoch 13/40\n",
      "189/189 [==============================] - 62s 329ms/step - loss: 0.6241 - acc: 0.8380 - val_loss: 0.5864 - val_acc: 0.8527\n",
      "Epoch 14/40\n",
      "189/189 [==============================] - 64s 339ms/step - loss: 0.5900 - acc: 0.8446 - val_loss: 0.6182 - val_acc: 0.8408\n",
      "Epoch 15/40\n",
      "189/189 [==============================] - 64s 339ms/step - loss: 0.5966 - acc: 0.8365 - val_loss: 0.6173 - val_acc: 0.8229\n",
      "Epoch 16/40\n",
      "189/189 [==============================] - 63s 335ms/step - loss: 0.5852 - acc: 0.8428 - val_loss: 0.5647 - val_acc: 0.8542\n",
      "Epoch 17/40\n",
      "189/189 [==============================] - 63s 332ms/step - loss: 0.5705 - acc: 0.8470 - val_loss: 0.5731 - val_acc: 0.8542\n",
      "Epoch 18/40\n",
      "189/189 [==============================] - 64s 338ms/step - loss: 0.5518 - acc: 0.8514 - val_loss: 0.5259 - val_acc: 0.8705\n",
      "Epoch 19/40\n",
      "189/189 [==============================] - 64s 338ms/step - loss: 0.5120 - acc: 0.8648 - val_loss: 0.5100 - val_acc: 0.8735\n",
      "Epoch 20/40\n",
      "189/189 [==============================] - 63s 335ms/step - loss: 0.4978 - acc: 0.8634 - val_loss: 0.5051 - val_acc: 0.8720\n",
      "Epoch 21/40\n",
      "189/189 [==============================] - 63s 331ms/step - loss: 0.4860 - acc: 0.8680 - val_loss: 0.4965 - val_acc: 0.8765\n",
      "Epoch 22/40\n",
      "189/189 [==============================] - 62s 330ms/step - loss: 0.4868 - acc: 0.8752 - val_loss: 0.4906 - val_acc: 0.8750\n",
      "Epoch 23/40\n",
      "189/189 [==============================] - 62s 327ms/step - loss: 0.4590 - acc: 0.8745 - val_loss: 0.4854 - val_acc: 0.8750\n",
      "Epoch 24/40\n",
      "189/189 [==============================] - 62s 326ms/step - loss: 0.4498 - acc: 0.8827 - val_loss: 0.4831 - val_acc: 0.8765\n",
      "Epoch 25/40\n",
      "189/189 [==============================] - 62s 326ms/step - loss: 0.4520 - acc: 0.8739 - val_loss: 0.4838 - val_acc: 0.8750\n",
      "Epoch 26/40\n",
      "189/189 [==============================] - 62s 327ms/step - loss: 0.4439 - acc: 0.8832 - val_loss: 0.4806 - val_acc: 0.8705\n",
      "Epoch 27/40\n",
      "189/189 [==============================] - 62s 327ms/step - loss: 0.4320 - acc: 0.8898 - val_loss: 0.4810 - val_acc: 0.8646\n",
      "Epoch 28/40\n",
      "189/189 [==============================] - 62s 328ms/step - loss: 0.4309 - acc: 0.8768 - val_loss: 0.4806 - val_acc: 0.8705\n",
      "Epoch 29/40\n",
      "189/189 [==============================] - 62s 327ms/step - loss: 0.4316 - acc: 0.8928 - val_loss: 0.4799 - val_acc: 0.8705\n",
      "Epoch 30/40\n",
      "189/189 [==============================] - 62s 328ms/step - loss: 0.4293 - acc: 0.8906 - val_loss: 0.4803 - val_acc: 0.8690\n",
      "Epoch 31/40\n",
      "189/189 [==============================] - 62s 328ms/step - loss: 0.4403 - acc: 0.8803 - val_loss: 0.4797 - val_acc: 0.8676\n",
      "Epoch 32/40\n",
      "189/189 [==============================] - 62s 329ms/step - loss: 0.4298 - acc: 0.8935 - val_loss: 0.4786 - val_acc: 0.8705\n",
      "Epoch 33/40\n",
      "189/189 [==============================] - 62s 331ms/step - loss: 0.4271 - acc: 0.8916 - val_loss: 0.4783 - val_acc: 0.8690\n",
      "Epoch 34/40\n",
      "189/189 [==============================] - 62s 326ms/step - loss: 0.4344 - acc: 0.8821 - val_loss: 0.4782 - val_acc: 0.8705\n",
      "Epoch 35/40\n",
      "189/189 [==============================] - 62s 327ms/step - loss: 0.4194 - acc: 0.8880 - val_loss: 0.4785 - val_acc: 0.8720\n",
      "Epoch 36/40\n",
      "189/189 [==============================] - 64s 339ms/step - loss: 0.4228 - acc: 0.8896 - val_loss: 0.4790 - val_acc: 0.8690\n",
      "Epoch 37/40\n",
      "189/189 [==============================] - 64s 340ms/step - loss: 0.4258 - acc: 0.8925 - val_loss: 0.4789 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 5e-07.\n",
      "Epoch 38/40\n",
      "189/189 [==============================] - 64s 339ms/step - loss: 0.4285 - acc: 0.8869 - val_loss: 0.4785 - val_acc: 0.8705\n",
      "Epoch 39/40\n",
      "189/189 [==============================] - 63s 332ms/step - loss: 0.4285 - acc: 0.8882 - val_loss: 0.4784 - val_acc: 0.8720\n",
      "Epoch 40/40\n",
      "189/189 [==============================] - 62s 326ms/step - loss: 0.4231 - acc: 0.8936 - val_loss: 0.4787 - val_acc: 0.8690\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train,\n",
    "                 validation_data = val,\n",
    "                 epochs = epochs,\n",
    "                 steps_per_epoch = len(x_train) // batch_size,\n",
    "                 callbacks=[checkpoint_acc, checkpoint_loss, lr_reducer, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYdmQVatH_e4"
   },
   "outputs": [],
   "source": [
    "# Variable to mark whether the model is Fine Tuned in exported CSV name\n",
    "fine_t = ''\n",
    "\n",
    "# Load model function (Choose between Loss and Accuracy)\n",
    "def load_model(num):\n",
    "  if num == 0:\n",
    "    model.load_weights(path_c + 'Loss_CP - ' + selected_model + fine_t + '.h5')\n",
    "  else:\n",
    "    model.load_weights(path_c + 'Acc_CP - ' + selected_model + fine_t + '.h5')\n",
    "\n",
    "load_model(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9214,
     "status": "ok",
     "timestamp": 1621528605125,
     "user": {
      "displayName": "He Did Nothing Wrong",
      "photoUrl": "",
      "userId": "14044224695877776076"
     },
     "user_tz": -180
    },
    "id": "QqiIls58RhPi",
    "outputId": "b45e5dee-3fc7-4dc0-fee2-b2a01e407033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 9s 296ms/step - loss: 0.3772 - acc: 0.9107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3771996796131134, 0.9107142686843872]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbMWf0QFHmq-"
   },
   "source": [
    "<a name=\"4.4\"></a>\n",
    "### &ensp; <font color='#008060'> *Fine Tuning* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OL_0_lx9Ht5Y"
   },
   "outputs": [],
   "source": [
    "# Unfreeze transfered model layers, besides batch normalization ones\n",
    "for layer in model.layers[unfreeze_layers:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate*0.01),\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2767016,
     "status": "ok",
     "timestamp": 1621528583242,
     "user": {
      "displayName": "He Did Nothing Wrong",
      "photoUrl": "",
      "userId": "14044224695877776076"
     },
     "user_tz": -180
    },
    "id": "aR1sBlAgwWW6",
    "outputId": "9bc208de-3344-4769-e66f-592c46fe32c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "189/189 [==============================] - 84s 385ms/step - loss: 0.7225 - acc: 0.7815 - val_loss: 0.5819 - val_acc: 0.8125\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 70s 368ms/step - loss: 0.5280 - acc: 0.8317 - val_loss: 0.5627 - val_acc: 0.8348\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 70s 373ms/step - loss: 0.4808 - acc: 0.8447 - val_loss: 0.5072 - val_acc: 0.8333\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 70s 373ms/step - loss: 0.4329 - acc: 0.8674 - val_loss: 0.4633 - val_acc: 0.8557\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 70s 369ms/step - loss: 0.4189 - acc: 0.8801 - val_loss: 0.4901 - val_acc: 0.8482\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 70s 369ms/step - loss: 0.3945 - acc: 0.8790 - val_loss: 0.5158 - val_acc: 0.8467\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 71s 374ms/step - loss: 0.3754 - acc: 0.8801 - val_loss: 0.4827 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 70s 369ms/step - loss: 0.3655 - acc: 0.8872 - val_loss: 0.5438 - val_acc: 0.8214\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 70s 371ms/step - loss: 0.3564 - acc: 0.8921 - val_loss: 0.6046 - val_acc: 0.8438\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 70s 372ms/step - loss: 0.3483 - acc: 0.8941 - val_loss: 0.5022 - val_acc: 0.8259\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 71s 373ms/step - loss: 0.3268 - acc: 0.8975 - val_loss: 1.0978 - val_acc: 0.6771\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 71s 374ms/step - loss: 0.3209 - acc: 0.9019 - val_loss: 1.0519 - val_acc: 0.7202\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 70s 368ms/step - loss: 0.3201 - acc: 0.9115 - val_loss: 0.5818 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 69s 367ms/step - loss: 0.3077 - acc: 0.9122 - val_loss: 1.0173 - val_acc: 0.7232\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 70s 373ms/step - loss: 0.2916 - acc: 0.9172 - val_loss: 0.4831 - val_acc: 0.8646\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 70s 371ms/step - loss: 0.2868 - acc: 0.9186 - val_loss: 0.4957 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 69s 367ms/step - loss: 0.2753 - acc: 0.9242 - val_loss: 0.4348 - val_acc: 0.8765\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 69s 367ms/step - loss: 0.2355 - acc: 0.9399 - val_loss: 0.3698 - val_acc: 0.9048\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 69s 366ms/step - loss: 0.2072 - acc: 0.9480 - val_loss: 0.3628 - val_acc: 0.9048\n",
      "Epoch 20/50\n",
      "189/189 [==============================] - 69s 367ms/step - loss: 0.1900 - acc: 0.9575 - val_loss: 0.3687 - val_acc: 0.9003\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 69s 368ms/step - loss: 0.1712 - acc: 0.9546 - val_loss: 0.3649 - val_acc: 0.9062\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 70s 372ms/step - loss: 0.1613 - acc: 0.9618 - val_loss: 0.3728 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 70s 373ms/step - loss: 0.1562 - acc: 0.9611 - val_loss: 0.3720 - val_acc: 0.8988\n",
      "Epoch 24/50\n",
      "189/189 [==============================] - 69s 367ms/step - loss: 0.1518 - acc: 0.9636 - val_loss: 0.3530 - val_acc: 0.9033\n",
      "Epoch 25/50\n",
      "189/189 [==============================] - 69s 367ms/step - loss: 0.1439 - acc: 0.9705 - val_loss: 0.3821 - val_acc: 0.9018\n",
      "Epoch 26/50\n",
      "189/189 [==============================] - 69s 367ms/step - loss: 0.1422 - acc: 0.9686 - val_loss: 0.3772 - val_acc: 0.9107\n",
      "Epoch 27/50\n",
      "189/189 [==============================] - 70s 368ms/step - loss: 0.1321 - acc: 0.9699 - val_loss: 0.3785 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "Epoch 28/50\n",
      "189/189 [==============================] - 69s 366ms/step - loss: 0.1260 - acc: 0.9747 - val_loss: 0.3788 - val_acc: 0.9092\n",
      "Epoch 29/50\n",
      "189/189 [==============================] - 69s 366ms/step - loss: 0.1259 - acc: 0.9743 - val_loss: 0.3824 - val_acc: 0.9062\n",
      "Epoch 30/50\n",
      "189/189 [==============================] - 70s 368ms/step - loss: 0.1247 - acc: 0.9738 - val_loss: 0.3835 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "Epoch 31/50\n",
      "189/189 [==============================] - 69s 367ms/step - loss: 0.1237 - acc: 0.9725 - val_loss: 0.3856 - val_acc: 0.9077\n",
      "Epoch 32/50\n",
      "189/189 [==============================] - 70s 370ms/step - loss: 0.1224 - acc: 0.9737 - val_loss: 0.3877 - val_acc: 0.9062\n",
      "Epoch 33/50\n",
      "189/189 [==============================] - 71s 374ms/step - loss: 0.1287 - acc: 0.9725 - val_loss: 0.3880 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "Epoch 34/50\n",
      "189/189 [==============================] - 71s 376ms/step - loss: 0.1282 - acc: 0.9715 - val_loss: 0.3881 - val_acc: 0.9092\n",
      "Epoch 35/50\n",
      "189/189 [==============================] - 70s 372ms/step - loss: 0.1173 - acc: 0.9760 - val_loss: 0.3872 - val_acc: 0.9092\n",
      "Epoch 36/50\n",
      "189/189 [==============================] - 71s 373ms/step - loss: 0.1277 - acc: 0.9731 - val_loss: 0.3868 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 5e-07.\n",
      "Epoch 37/50\n",
      "189/189 [==============================] - 70s 371ms/step - loss: 0.1211 - acc: 0.9750 - val_loss: 0.3864 - val_acc: 0.9092\n",
      "Epoch 38/50\n",
      "189/189 [==============================] - 69s 367ms/step - loss: 0.1239 - acc: 0.9739 - val_loss: 0.3875 - val_acc: 0.9092\n",
      "Epoch 39/50\n",
      "189/189 [==============================] - 70s 369ms/step - loss: 0.1223 - acc: 0.9737 - val_loss: 0.3886 - val_acc: 0.9092\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train,\n",
    "                    validation_data = val,\n",
    "                    epochs = fine_tune_epochs,\n",
    "                    steps_per_epoch = len(x_train) // batch_size,\n",
    "                    callbacks = [checkpoint_acc_ft, checkpoint_loss_ft, lr_reducer,lr_scheduler, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NLlnRYmIkr_"
   },
   "outputs": [],
   "source": [
    "# Changed to fine tuned\n",
    "fine_t = ' FT'\n",
    "\n",
    "# Loead weights that achieved the highest accuracy\n",
    "load_model(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRLXEVJIzeHr"
   },
   "source": [
    "<a name=\"5\"></a>\n",
    "## <font color='#99b3e6'> 5. Predictions </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcsIDDeR8P2l"
   },
   "source": [
    "<a name=\"5.1\"></a>\n",
    "### &ensp; <font color='#008060'> *Test Images* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGEXPqE7APov"
   },
   "outputs": [],
   "source": [
    "# Read Test Images\n",
    "test_name = []\n",
    "x_test = []\n",
    "for img in os.listdir(test_path):\n",
    "  img_array = cv2.imread(os.path.join(test_path, img))\n",
    "  res_array = cv2.resize(img_array, (img_size, img_size))\n",
    "  test_name.append(img)\n",
    "  x_test.append(res_array)\n",
    "\n",
    "x_test = np.array(x_test).reshape(-1, img_size, img_size, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHSkLL1b8Utj"
   },
   "source": [
    "<a name=\"5.2\"></a>\n",
    "### &ensp; <font color='#008060'> *Export Predictions* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24653,
     "status": "ok",
     "timestamp": 1621528666297,
     "user": {
      "displayName": "He Did Nothing Wrong",
      "photoUrl": "",
      "userId": "14044224695877776076"
     },
     "user_tz": -180
    },
    "id": "647kSdIUnAfm",
    "outputId": "d5665870-f610-4b25-e45b-7b2302bfac5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 11s 291ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "result =  model.predict(x_test)\n",
    "softmax = model.predict(x_test, verbose=1)\n",
    "\n",
    "# get predict label\n",
    "predict_label = np.argmax(result,axis=-1)\n",
    "\n",
    "# Export CSV\n",
    "Submission = pd.DataFrame(list(zip(test_name, predict_label)), columns = [colx, coly])\n",
    "Submission.to_csv(sub + selected_model + ' - (' + str(img_size) + ',' + str(epochs) + ',' + str(batch_size) + ',' + str(learning_rate) + ',' + str(fine_tune_epochs) + ',' + str(unfreeze_layers) + ')' + fine_t + '.csv', index = False)\n",
    "\n",
    "Softmax = pd.DataFrame(softmax)\n",
    "Softmax.to_csv(sub + 'Softmax - ' + selected_model + ' - (' + str(img_size) + ',' + str(epochs) + ',' + str(batch_size) + ',' + str(learning_rate) + ',' + str(fine_tune_epochs) + ',' + str(unfreeze_layers) + ')' + fine_t + '.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGC99QBZ4ZUA"
   },
   "source": [
    "<a name=\"5.3\"></a>\n",
    "### &ensp; <font color='#008060'> *Voting Ensemble* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAj_lxBdEBtj"
   },
   "outputs": [],
   "source": [
    "# Soft Voting\n",
    "soft = os.listdir(soft_path)\n",
    "\n",
    "# Create an array of zeros, with 3 columns, for each class, and columns equal\n",
    "# to the number of test images.\n",
    "# Read the CSVs from the path and sums the softmaxes values of all CSVs\n",
    "soft_predictions = np.zeros([len(test_name), num_cl])\n",
    "for soft_csv in soft:\n",
    "  predictions = pd.read_csv(soft_path+'/'+soft_csv, dtype=float)\n",
    "  soft_predictions = np.sum([soft_predictions, predictions], axis=0)\n",
    "\n",
    "# Returns the index of the biggest value by row. Which is equal to the class.\n",
    "soft_final = np.argmax(soft_predictions, axis=1)\n",
    "\n",
    "results = pd.DataFrame(list(zip(test_name, soft_final)),\n",
    "                       columns = [colx, coly])\n",
    "results.to_csv(soft_single, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPc8zi+IKEPEYnx14hGQtVo",
   "collapsed_sections": [],
   "name": "Effi x6 - Local.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
